# Second Voice MVP

An offline-first, accessibility-focused real-time transcription and speaker diarization tool for deaf/hard-of-hearing users.

## ğŸ¯ SANAD Challenge Submission
**Category:** Accessibility, Inclusion, and Dignity - Hearing Impairment

## ğŸ“ Project Structure

```
SecondVoice_MVP/
â”œâ”€â”€ mobile_app/          # Flutter cross-platform app
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ screens/     # UI screens
â”‚       â”œâ”€â”€ widgets/     # Reusable components
â”‚       â”œâ”€â”€ services/    # Audio & AI services
â”‚       â””â”€â”€ models/      # Data models
â””â”€â”€ ai_engine/           # Python prototyping
    â”œâ”€â”€ models/          # Vosk model files
    â””â”€â”€ *.py             # Transcription & diarization
```

## ğŸš€ Quick Start

### First-Time Setup (Required)

The Flutter project needs platform files generated. Run this **once**:

```bash
cd mobile_app
flutter create . --project-name second_voice --org com.sanad --platforms=linux,android,ios
```

### Then Run the App

```bash
# Linux Desktop
flutter run -d linux

# Android (with device connected)
flutter run -d android

# Get dependencies first
flutter pub get
```

### AI Engine (Python - for testing)
```bash
cd ai_engine
pip install -r requirements.txt
python transcribe_demo.py --demo
```

## âœ¨ Features

- **Offline-First**: Runs entirely on-device using Vosk
- **Speaker Diarization**: Color-coded speaker identification
- **High Accessibility**: Dark mode, adjustable text, haptic feedback
- **Privacy**: No data leaves the device

## ğŸ“‹ Requirements

- Flutter 3.x
- Python 3.8+
- Vosk model: `vosk-model-small-en-us-0.15` (download from [Vosk Models](https://alphacephei.com/vosk/models))

## ğŸ“± Vosk Model Setup

1. Download the model: `vosk-model-small-en-us-0.15`
2. Extract to: `mobile_app/assets/models/vosk-model-small-en-us-0.15/`
